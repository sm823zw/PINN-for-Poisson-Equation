{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = '#D7E5E5'\n",
    "mpl.rcParams['font.family']= 'sans-serif'\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['font.weight'] = 'bold'\n",
    "mpl.rcParams['legend.title_fontsize'] = 10\n",
    "mpl.rcParams['savefig.facecolor']= 'white'\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['legend.fontsize'] = 10\n",
    "mpl.rcParams['axes.labelweight'] = 'heavy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/data_y_100_100_58_vgs_100_50_100.csv'\n",
    "data_f = pd.read_csv(path)\n",
    "\n",
    "path = '../Data/data_bc1_vgs_100_50_100.csv'\n",
    "data_bc1 = pd.read_csv(path)\n",
    "\n",
    "path = '../Data/data_bc2_vgs_100_50_100.csv'\n",
    "data_bc2 = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = data_f[data_f['Vgs'] >= 0]\n",
    "data_bc1 = data_bc1[data_bc1['Vgs'] >= 0]\n",
    "data_bc2 = data_bc2[data_bc2['Vgs'] >= 0]\n",
    "\n",
    "# Comment the above three lines and uncomment the below three lines for training the model in other range\n",
    "# data_f = data_f[data_f['Vgs'] <= 0.2]\n",
    "# data_bc1 = data_bc1[data_bc1['Vgs'] <= 0.2]\n",
    "# data_bc2 = data_bc2[data_bc2['Vgs'] <= 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "n_batches = len(data_f.index)/batch_size\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_f.drop('psi', axis = 1).values.astype(np.float32)\n",
    "y = data_f['psi'].values.astype(np.float32)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.tensor(X).to(device)\n",
    "train_target = torch.tensor(y).to(device)\n",
    "train_tensor = TensorDataset(train, train_target)\n",
    "train_loader = DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.mean(train, axis=0)\n",
    "std = torch.std(train, axis=0)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bc1 = data_bc1.drop('psi', axis = 1).values.astype(np.float32)\n",
    "y_bc1 = data_bc1['psi'].values.astype(np.float32)\n",
    "train_bc1 = torch.tensor(X_bc1, requires_grad=True).to(device)\n",
    "train_target_bc1 = torch.tensor(y_bc1).to(device)\n",
    "\n",
    "X_bc2 = data_bc2.drop('psi', axis = 1).values.astype(np.float32)\n",
    "y_bc2 = data_bc2['psi'].values.astype(np.float32)\n",
    "train_bc2 = torch.tensor(X_bc2, requires_grad=True).to(device)\n",
    "train_target_bc2 = torch.tensor(y_bc2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_SC1(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden, n_layers):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.parameter.Parameter(data=torch.ones(1))\n",
    "        self.fcs = nn.Sequential(*[\n",
    "            nn.Linear(n_input, n_hidden),\n",
    "            nn.Tanh(),\n",
    "        ])\n",
    "        self.fch = nn.Sequential(*[\n",
    "            nn.Sequential(*[\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.Tanh(),\n",
    "            ]) for _ in range(n_layers - 1)\n",
    "        ])\n",
    "        self.fce = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x-mean)/std\n",
    "        x = self.alpha*x\n",
    "        x = torch.exp(x)\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x\n",
    "\n",
    "class NN_SC2(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden, n_layers):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.parameter.Parameter(data=-1*torch.ones(1))\n",
    "        self.fcs = nn.Sequential(*[\n",
    "            nn.Linear(n_input, n_hidden),\n",
    "            nn.Tanh(),\n",
    "        ])\n",
    "        self.fch = nn.Sequential(*[\n",
    "            nn.Sequential(*[\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.Tanh(),\n",
    "            ]) for _ in range(n_layers - 1)\n",
    "        ])\n",
    "        self.fce = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x-mean)/std\n",
    "        x = self.alpha*x\n",
    "        x = torch.exp(x)\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN_SC1(2, 1, 20, 8).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epoch_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 250, gamma=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_A = 1e22\n",
    "t_ox = 1e-9\n",
    "t_si = 4e-7\n",
    "epsilon_0 = 8.85418781e-12\n",
    "epsilon_si = epsilon_0*11.9\n",
    "epsilon_sio2 = epsilon_0*3.9\n",
    "delta_psi_MS = 0.21\n",
    "psi_t = 26e-3\n",
    "n_i = 1e16\n",
    "psi_F = psi_t*math.log(N_A/n_i)\n",
    "q = 1.6e-19\n",
    "p_o = N_A\n",
    "n_o = n_i**2/N_A\n",
    "A = q*N_A/epsilon_si\n",
    "B = epsilon_sio2/(t_ox*epsilon_si)\n",
    "C = np.exp(-2*psi_F/psi_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50000\n",
    "loss = nn.MSELoss(reduction='sum')\n",
    "min_loss = 9999\n",
    "\n",
    "loss_tot, loss_1, loss_2, loss_3, loss_4, loss_5 = [], [], [], [], [], []\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    mse, mse_1, mse_2, mse_3, mse_4, mse_5 = 0, 0, 0, 0, 0, 0\n",
    "    for X, psi_true in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X.requires_grad = True\n",
    "        psi_pred = model(X).squeeze()\n",
    "        l1 = loss(psi_pred, psi_true)\n",
    "        \n",
    "        d_psi = torch.autograd.grad(psi_pred, X, torch.ones_like(psi_pred), create_graph=True)[0]\n",
    "        d_psi_2 = torch.autograd.grad(d_psi, X, torch.ones_like(d_psi), create_graph=True)[0]\n",
    "        d_psi_2 = d_psi_2[:, 0]\n",
    "        f = d_psi_2 / A + (torch.exp(-psi_true/psi_t) - 1 - C*(torch.exp(psi_true/psi_t) - 1))\n",
    "        l2 = loss(f, torch.zeros_like(f))\n",
    "        \n",
    "        psi_bc1_pred = model(train_bc1).squeeze()\n",
    "        d_psi_bc1 = torch.autograd.grad(psi_bc1_pred, train_bc1, torch.ones_like(psi_bc1_pred), create_graph=True)[0]\n",
    "        d_psi_bc1 = d_psi_bc1[:, 0]\n",
    "\n",
    "        bc1 = d_psi_bc1 / B + (train_bc1[:, 1] - train_target_bc1)\n",
    "        l3 = loss(bc1, torch.zeros_like(bc1))\n",
    "\n",
    "        psi_bc2_pred = model(train_bc2).squeeze()\n",
    "        bc2 = psi_bc2_pred\n",
    "        l4 = loss(bc2, torch.zeros_like(bc2))\n",
    "        \n",
    "        Q = 10*d_psi\n",
    "        Q = torch.sigmoid(Q)\n",
    "        l5 = loss(Q, torch.zeros_like(Q))\n",
    "\n",
    "        l1 /= X.shape[0]\n",
    "        l2 /= X.shape[0]\n",
    "        l3 /= train_bc1.shape[0]\n",
    "        l4 /= train_bc2.shape[0]\n",
    "        l5 /= X.shape[0]\n",
    "        \n",
    "        l = l1 + 1e-10*l2 + 1e-2*l3 + l4 + 1e-5*l5\n",
    "        \n",
    "        l.backward()\n",
    "        mse += l.item()\n",
    "        mse_1 += l1.item()\n",
    "        mse_2 += l2.item()\n",
    "        mse_3 += l3.item()\n",
    "        mse_4 += l4.item()\n",
    "        mse_5 += l5.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    mse /= n_batches\n",
    "    mse_1 /= n_batches\n",
    "    mse_2 /= n_batches\n",
    "    mse_3 /= n_batches\n",
    "    mse_4 /= n_batches\n",
    "    mse_5 /= n_batches\n",
    "\n",
    "    epoch_scheduler.step()\n",
    "\n",
    "    if min_loss > mse**0.5:\n",
    "        min_loss = mse**0.5\n",
    "        torch.save(model.state_dict(), \"model.pt\")\n",
    "    loss_tot.append(mse)\n",
    "    loss_1.append(mse_1)\n",
    "    loss_2.append(mse_2)\n",
    "    loss_3.append(mse_3)\n",
    "    loss_4.append(mse_4)\n",
    "    loss_5.append(mse_5)\n",
    "    if i%10 == 0:\n",
    "        print('Epoch: ' + str(i) + ' MSE: ' + str(mse) + \n",
    "              ' MSE 1: ' + str(mse_1) + ' MSE 2: ' + str(mse_2) + \n",
    "              ' MSE 3: ' + str(mse_3) + ' MSE 4: ' + str(mse_4) +\n",
    "              ' MSE 5: ' + str(mse_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig.set_dpi(200)\n",
    "plt.plot(np.log10(loss_tot))\n",
    "plt.plot(np.log10(loss_1))\n",
    "plt.plot(np.log10(loss_2))\n",
    "plt.plot(np.log10(loss_3))\n",
    "plt.plot(np.log10(loss_4))\n",
    "plt.plot(np.log10(loss_5))\n",
    "plt.legend(['Total loss', 'MSE $\\psi$', 'Loss Physics', 'Loss bc1', 'Loss bc2', 'Loss mono'], fontsize=15)\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Loss ($log_{10}$ scale)', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.title('Training losses', fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ba01e4fa65b88f119ce3c866a0b8e9aa80a952402cad57d84cd82382e74df68"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch1.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
